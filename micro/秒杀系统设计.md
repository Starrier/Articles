# 秒杀系统

## 难点

1. 突发大流量
2. 超卖
3. 性能

## 主要思路

1. 限流
2. 削峰
3. 异步
4. 缓存

1）对于大促时候的秒杀活动，一般运营会配置静态的活动页面，配置静态活动页面主要有两个目的一方面是为了便于在各种社交媒体分发，另一方面是因为秒杀活动页的流量是大促期间最大的，通过配置成静态页面可以将页面发布在公有云上动态的横向扩展；
2）将秒杀活动的静态页面提前刷新到CDN节点，通过CDN节点的页面缓存来缓解访问压力和公司网络带宽，CDN上缓存js、css和图片；
3）将活动H5页面部署在公有云的web  server上，使用公有云最大的好处就是能够根据活动的火爆程度动态扩容而且成本较低，同时将访问压力隔离在公司系统外部；
4）在提供真正商品秒杀业务功能的app server上，需要进行交易限流、熔断控制，防止因为秒杀交易影响到其他正常服务的提供，我们在限流和熔断方面使用了hystrix，在核心交易的controller层通过hystrix进行交易并发限流控制，当交易流量超出我们设定的限流最大值时，会对新交易进行熔断处理固定返回静态失败报文。
5）服务降级处理，除了上面讲到的限流和熔断控制，我们还设定了降级开关，对于首页、购物车、订单查询、大数据等功能都会进行一定程度的服务降级，例如我们会对首页原先动态生成的大数据页面布局降级为所有人看到的是一样的页面、购物车也会降级为不在一级页面的tabbar上的购物车图标上显示商品数量、历史订单的查询也会提供时间周期较短的查询、大数据商品推荐也会提供一样的商品推荐，通过这样的降级处理能够很好的保证各个系统在大促期间能够正常的提供最基本的服务，保证用户能够正常下单完成付款。
6）上面介绍的都是如何保证能扛住高并发，下面介绍下整个方案中如何防止超卖现象的发生，我们日常的下单过程中防止超卖一般是通过在数据库上实施乐观锁来完成，使用乐观锁虽然比for update这种悲观锁方式性能要好很多，但是还是无法满足秒杀的上万并发需求，我们的方案其实也很简单实时库存的扣减在缓存中进行，异步扣减数据库中的库存，保证缓存中和数据库中库存的最终一致性。
在这个方案中我们使用的分布式缓存是redis，使用了codis集群方案稳定性和高可用方面还是比较有保证的，因为redis是单线程写，所以也不用担心线程安全的问题，redis自身就能够保证数据的强一致性，在下单的事务中包含了实时扣减缓存中的库存和异步发送队列，由队列处理器再异步从队列中取出订单根据订单信息扣减库存系统数据库中的商品数量。
总结
整个秒杀方案就介绍这么多，其实整个的思路还是比较简单的，也没有特别复杂的地方，对于大部分公司的高并发场景还是适用的，并且比较容易实施上线，该方案对于我们当时每秒几万的并发场景是能够扛住的，但是对于像小米、12306这些在高峰时动不动几十万用户并发的场景，使用这样的方案可能用户体验方面和系统服务方面就会存在一些问题了，对于每秒几十万并发的场景我们一般除了会在技术层面进行优化，更多的会通过其他一些业务手段来进行交易分流来分散整体的高并发访问，秒杀方案就介绍到这里，具体的实现这里就不写了，我相信跟着上面介绍的思路很容易就能将代码写出来。

作者：monkey01
链接：https://www.jianshu.com/p/d789ea15d060
来源：简书
简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。